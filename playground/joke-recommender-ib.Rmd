---
title: "Jokes Recommender ver. 1"
author: "Igor Baranov"
date: "January 22, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Init libraries
set.seed(777)

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
if(! "recommenderlab" %in% installed.packages()) 
  install.packages("recommenderlab", depend = TRUE)
if(! "readr" %in% installed.packages()) 
  install.packages("readr", depend = TRUE)
if(! "RDSTK" %in% installed.packages()) 
  install.packages("RDSTK", depend = TRUE)

library("recommenderlab")
library("ggplot2")
library("readr")
library("RDSTK")
library("Matrix")

```

## Set directory to current script (works in R Studio only)
```{r}
#this.dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
#setwd(this.dir)
```

# Load the jokes rating data
```{r message=FALSE, warning=FALSE}
df <- read_csv(file="../data/jesterfinal151cols.csv.zip",col_names = FALSE)

#Rename columns as per their "Joke ID" and columns to the userid
names(df)     <- c("RATINGS",1:(ncol(df)-1))
row.names(df) <- c(1:nrow(df))

#replace all 99 ratings with NA so we can filter them out
df[,2:ncol(df)][df[,2:ncol(df)]==99]<-NA
df
```

## Load the jokes text
```{r message=FALSE, warning=FALSE}
jokes <- read_tsv(file="../data/jester_items.tsv",col_names = FALSE)
jokes <- jokes['X2']
head(jokes)
```

## What's the distribution of rating count? Many jokes probably have 0 ratings.
```{r}
ratingcount<-nrow(df)-colSums(is.na(df[,2:ncol(df)]))
summary(ratingcount)
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
ggplot() + aes(ratingcount)+ geom_histogram(colour="black", fill="white")+
  ylab("Number of Jokes")+
  xlab("Number of Ratings")
```

## How many users have given a reasonable amount of ratings?
```{r}
ratingcount_u<-as.vector(df[[1]])
summary(ratingcount_u)
```

```{r message=FALSE, warning=FALSE}
ggplot() + aes(ratingcount_u)+ geom_histogram(colour="black", fill="white")+
  ylab("Number of Users")+
  xlab("Number of Ratings Given")
```

## Get sentiment score for jokes to see if there's any relation to joke rating and sentiment
```{r}
jokes[,2]<-1
jokes[,3]<-1
colnames(jokes)<-c("Joke","Sentiment","AvgRating")
head(jokes)
```

```{r}
for (i in 1:nrow(jokes)) {
  jokes[i,2]<-text2sentiment(jokes[[i,1]])
}
```


```{r}
for (i in 1:nrow(jokes)) {
  jokes[i,3]<- median(df[[i+1]],na.rm=TRUE)
}
jokes
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
ggplot(data=jokes, mapping = aes(x=jokes$Sentiment,y=jokes$AvgRating)) +
  geom_point()+
  ggtitle("Sentiment vs Median Rating")+
  ylab("Median Rating") + xlab("Sentiment Score")
```

# Use with Recommender Lab library
## Convert data to realRatingMatrix object

```{r message=FALSE, warning=FALSE}
s<-as(df[,2:ncol(df)], "matrix")
dimnames(s) <- list(rownames(s, do.NULL = FALSE, prefix = "u"),
                    colnames(s, do.NULL = FALSE, prefix = "j"))
s<-as(dropNA(s), "sparseMatrix")
rm <- new("realRatingMatrix",data=s)
rm
```

## Visualizing ratings

```{r}
qplot(getRatings(rm), binwidth = 1, 
      main = "Histogram of ratings", xlab = "Rating", ylab = "Number of users")
```

## Check how many jokes have the users rated
```{r}
summary(rowCounts(rm))

nusers=dim(rm)[1]
njokes=dim(rm)[2]

```

## Visualise a part of the ratings matrix. There is lots of missing data!
```{r}
image(rm[sample(nusers,25),sample(njokes,25)])
```

## Visualizing a sample of ratings

```{r fig.height=10, fig.width=6, message=FALSE, warning=FALSE, paged.print=FALSE}
image(sample(rm, 500), main = "Raw ratings")
```

# Skewed to the right
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
summary(getRatings(rm)) 
```

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
qplot(getRatings(normalize(rm, method = "Z-score")),
      main = "Histogram of normalized ratings", xlab = "Rating") 

```

## use only users with more than 50 ratings
```{r}
Jokes50 <- rm[rowCounts(rm) >50,]
Jokes50
```

# This distribution seems better than the one done for all the users
```{r}
summary(getRatings(normalize(Jokes50, method = "Z-score"))) 
```

# Seems people get tired of rating jokes at a logarithmic pace. But most rate some.
```{r}
qplot(rowCounts(rm), binwidth = 10, 
      main = "Jokes Rated on average", 
      xlab = "# of Users", 
      ylab = "# of Jokes rated")
```

## Present mean rating of jokes
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
qplot(colMeans(rm), binwidth = .5, 
      main = "Mean rating of Jokes", 
      xlab = "Rating", 
      ylab = "# of jokes")
```

## Train a user-based collaborative filtering recommender using a small training set.

 The big spike on 1 suggests that this could also be intepreted as binary
 In other words, some people don't want to see certain jokes at all.
 Same on 5 and on 3. We can give it the binary treatment later

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
recommenderRegistry$get_entries(dataType = "realRatingMatrix")
train <- Jokes50[1:500]
```

We have a few options
```{r}

scheme <- evaluationScheme(Jokes50, method = "split", train = .9,
                           k = 1, given = 10, goodRating = 4)
scheme
```

Let's check some algorithms against each other
```{r}
tr <- getData(scheme, "train"); tr
tst_known <- getData(scheme, "known"); tst_known
tst_unknown <- getData(scheme, "unknown"); tst_unknown
```

```{r}
algorithms <- list(
  "random items" = list(name="RANDOM", param=list(normalize = "Z-score")),
  "popular items" = list(name="POPULAR", param=list(normalize = "Z-score")),
  "user-based CF" = list(name="UBCF", param=list(normalize = "Z-score",
                                                 method="Cosine",
                                                 nn=50))
)
```

## run algorithms, predict next n jokes (list)
```{r}
results <- evaluate(scheme, algorithms, n=c(1, 3, 5, 10, 15, 20))
```

## Draw ROC curve
```{r}
plot(results, annotate = 1:4, legend="topleft")
```

## create a user-based CF recommender using training data
```{r}
rcmnd_ub <- Recommender(tr, "UBCF", param=list(method="pearson",nn=50))
```

## create predictions for the test users using known ratings
```{r}
pred_ub <- predict(rcmnd_ub, tst_known, type="ratings"); pred_ub
```

## evaluate recommendations on "unknown" ratings
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
acc_ub <- calcPredictionAccuracy(pred_ub, tst_unknown);
as(acc_ub,"matrix")
```

##compare predictions with true "unknown" ratings
```{r}
as(tst_unknown, "matrix")[1:8,1:5]
as(pred_ub, "matrix")[1:8,1:5]
```

## Create top-N recommendations for new users (users 1000 and 1001)
```{r}
pre <- predict(rcmnd_ub, Jokes50[1000:1001], n = 10)
pre
```

## Recommendations as 'topNList' with n = 10 for 2 users. 
```{r}
as(pre, "list")
```

## Create a 'new' user ratings and recomment next joke

```{r message=FALSE, warning=FALSE}
# create a random matrix with ratings
rr <- sample(c(NA,0:5),ncol(df)-1, replace=TRUE, prob=c(.7,rep(.3/6,6)))

## coerce into a realRatingMAtrix
m <- matrix(rr,
	nrow=1, ncol=(ncol(df)-1), dimnames = list(
	    user=paste('u', 1:1, sep=''),
	    item=paste('i', 1:(ncol(df)-1), sep='')
    ))
print (m)

ratings.new <- as(m, "realRatingMatrix")
print (ratings.new)

# recommend next joke
recNext <- predict(rcmnd_ub, ratings.new, n = 1)
recNum<-as(recNext, "list")

sprintf("The next recommended joke is %s", recNum[[1]])
print (jokes[recNum[[1]],1])
```


# Now let's prepare data for the Shiny app

## Saving recommender data objects
```{r}
saveRDS(rcmnd_ub, file = "jokeRecommender.Rds")
saveRDS(jokes, file = "jokes.Rds")
```